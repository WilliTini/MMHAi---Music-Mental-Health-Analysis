# ğŸ§  Machine Learning Analysis - Spiegazione Completa

## Progetto: Analisi Musica e Salute Mentale

---

## ğŸ¯ **PROGETTO COMPLETO: ANALISI MUSICA E SALUTE MENTALE**

### **FASE 1: PREPROCESSING E PULIZIA DATI**

#### ğŸ”§ **Cosa abbiamo fatto:**
```python
# Caricamento e pulizia dataset
df = pd.read_csv('data/mxmh_survey_results.csv')
df = df.dropna(subset=['Depression', 'Anxiety', 'Insomnia', 'OCD'])
```

#### ğŸ“š **Teoria:**
- **Missing Data Handling**: Abbiamo rimosso righe con valori mancanti nelle variabili target (salute mentale) perchÃ© sono essenziali per l'analisi
- **Data Quality**: La qualitÃ  dei dati Ã¨ fondamentale - "garbage in, garbage out"
- **Standardizzazione**: Abbiamo convertito le scale ordinali (Never=0, Rarely=1, Sometimes=2, Very frequently=3) per renderle numeriche

---

### **FASE 2: ANALISI ESPLORATIVA (EDA)**

#### ğŸ”§ **Cosa abbiamo fatto:**
- Distribuzioni delle variabili
- Matrici di correlazione
- Visualizzazioni dei pattern

#### ğŸ“š **Teoria:**
- **Exploratory Data Analysis (EDA)**: Prima di applicare algoritmi, bisogna capire i dati
- **Correlazione â‰  Causazione**: Le correlazioni mostrano associazioni, non cause
- **Spearman vs Pearson**: Usiamo Spearman perchÃ© i nostri dati sono ordinali, non necessariamente lineari

---

### **FASE 3: CLUSTERING**

#### ğŸ”§ **Cosa abbiamo fatto:**
```python
# K-means clustering sulle variabili di salute mentale
kmeans = KMeans(n_clusters=2, random_state=42)
clusters = kmeans.fit_predict(mental_health_data)
```

#### ğŸ“š **Teoria :**

**ğŸ§  PerchÃ© K-means?**
- **Algoritmo centroide-based**: Minimizza la varianza intra-cluster
- **Formula obiettivo**: Minimizza Î£ ||xi - Î¼j||Â² dove Î¼j Ã¨ il centroide del cluster j
- **Convergenza garantita**: L'algoritmo converge sempre (Lloyd's algorithm)

**ğŸ¯ PerchÃ© 2 cluster?**
- **Silhouette Score**: Metrica che misura quanto bene separati sono i cluster
- **Formula**: s(i) = (b(i) - a(i)) / max(a(i), b(i))
  - a(i) = distanza media intra-cluster
  - b(i) = distanza media al cluster piÃ¹ vicino
- **Range [-1, 1]**: 1 = perfetto, 0 = sovrapposizione, -1 = mal clusterizzato


### **FASE 4A: ANALISI STATISTICA**

#### ğŸ”§ **Cosa abbiamo fatto:**
- T-test per confrontare generi musicali tra cluster
- Correlazioni di Spearman
- Test di significativitÃ 

#### ğŸ“š **Teoria statistica:**

**ğŸ“Š T-test (Welch's):**
```python
t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)
```
- **Ipotesi nulla (Hâ‚€)**: Le medie sono uguali
- **Ipotesi alternativa (Hâ‚)**: Le medie sono diverse
- **Welch's t-test**: Non assume varianze uguali (piÃ¹ robusto)
- **Formula**: t = (xÌ„â‚ - xÌ„â‚‚) / âˆš(sâ‚Â²/nâ‚ + sâ‚‚Â²/nâ‚‚)

**ğŸ¯ Cohen's d (Effect Size):**
```python
cohens_d = (mean1 - mean2) / pooled_std
```
- **Interpretazione**: 
  - 0.2 = piccolo effetto
  - 0.5 = medio effetto  
  - 0.8 = grande effetto
- **PerchÃ© importante**: p-value dice SE c'Ã¨ differenza, Cohen's d dice QUANTO Ã¨ grande

**ğŸ“ˆ Correlazione di Spearman:**
- **Formula**: Ï = 1 - (6Î£dÂ²) / (n(nÂ²-1))
- **Vantaggio su Pearson**: Cattura relazioni monotone non lineari
- **Range [-1, 1]**: Come Pearson ma piÃ¹ robusto

**ğŸ”¬ Correzione per test multipli:**
- **Problema**: Se fai 100 test con Î±=0.05, aspetti 5 falsi positivi
- **Non applicata**: PerchÃ© volevamo essere esplorativi, non confermativi

---

### **FASE 5: MACHINE LEARNING**

#### ğŸ”§ **Cosa abbiamo fatto:**
- **Classificazione**: Predire cluster da variabili musicali
- **Regressione**: Predire severity score da musica

#### ğŸ“š **Teoria ML approfondita:**

**ğŸ¯ Logistic Regression (Classificazione):**
```python
# Funzione logistica: p = 1/(1 + e^(-z))
# dove z = Î²â‚€ + Î²â‚xâ‚ + Î²â‚‚xâ‚‚ + ... + Î²â‚™xâ‚™
```
- **PerchÃ© funziona meglio**: Dataset lineare separabile nei nostri dati
- **InterpretabilitÃ **: I coefficienti Î² sono interpretabili
- **Regularizzazione**: Previene overfitting automaticamente

**ğŸŒ³ Random Forest:**
```python
# Ensemble di decision trees
# Voto finale = maggioranza dei tree
```
- **Vantaggio**: Cattura interazioni non lineari
- **Svantaggio**: Meno interpretabile
- **Feature Importance**: Misura quanto ogni feature riduce l'impuritÃ 

**ğŸ“Š Cross-Validation:**
```python
cv_scores = cross_val_score(model, X, y, cv=5)
```
- **Scopo**: Stima performance su dati non visti
- **K-fold (k=5)**: Divide dati in 5 parti, testa su 1, training su 4
- **Bias-Variance tradeoff**: CV aiuta a bilanciare

**ğŸ“ˆ Metriche di valutazione:**

**Classificazione:**
- **Accuracy = (TP + TN) / (TP + TN + FP + FN)**
- **F1-Score = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)**
- **PerchÃ© F1**: Bilancia precision e recall, buono per dataset sbilanciati

**Regressione:**
- **RÂ² = 1 - (SS_res / SS_tot)**
  - SS_res = Î£(yi - Å·i)Â² (errore residuo)
  - SS_tot = Î£(yi - È³)Â² (varianza totale)
- **RMSE = âˆš(MSE)**: Stessa unitÃ  della variabile target

---

## ğŸ§  **ANALISI DEL CODICE MACHINE LEARNING**

### **1. IMPORT E SETUP**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.metrics import accuracy_score, f1_score, r2_score, mean_squared_error
from sklearn.metrics import classification_report, confusion_matrix
```

**ğŸ” Spiegazione:**
- **pandas/numpy**: Manipolazione dati
- **matplotlib/seaborn**: Visualizzazioni
- **sklearn**: Libreria ML principale
- **model_selection**: Split dati e validazione
- **preprocessing**: Standardizzazione features
- **ensemble**: Algoritmi ensemble (Random Forest)
- **linear_model**: Regressione lineare e logistica
- **metrics**: Metriche di performance

---


**ğŸ” Teoria:**
- **Feature Engineering**: Abbiamo separato generi musicali da comportamenti
- **Domain Knowledge**: Basato sulla teoria musicale e psicologica
- **Manual Selection**: Meglio dell'automatic feature selection per interpretabilitÃ 

```python
    # Seleziona solo features disponibili nel dataset
    available_features = []
    for col in music_genres + music_behaviors:
        if col in df.columns:
            available_features.append(col)
    
    X = df[available_features].fillna(df[available_features].median())
```

**ğŸ” Spiegazione tecnica:**
- **Defensive Programming**: Controlla che le colonne esistano
- **Missing Data Strategy**: Median imputation
  - **PerchÃ© median?** PiÃ¹ robusta agli outlier della mean
  - **Alternative**: Mode per categoriche, KNN imputation per dati complessi

```python
    y_cluster = df['Cluster']
    
    # Severity score = media delle 4 variabili mentali
    mental_vars = ['Depression', 'Anxiety', 'Insomnia', 'OCD']
    y_severity = df[mental_vars].mean(axis=1)
```

**ğŸ” Teoria dello score composito:**
- **Latent Variable**: Severity score rappresenta un fattore latente "distress psicologico"
- **Formula**: Severity = (Depression + Anxiety + Insomnia + OCD) / 4
- **Vantaggio**: Riduce noise, cattura pattern comune
- **ValiditÃ **: Supportata da teoria dei disturbi internalizzanti

---

### **3. CLASSIFICAZIONE**

```python
def classification_analysis(X, y_cluster, feature_names):
    # Standardizzazione
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
```

**ğŸ” Standardizzazione profonda:**
```python
# Formula: z = (x - Î¼) / Ïƒ
# Dove Î¼ = media, Ïƒ = deviazione standard
```
- **PerchÃ© necessaria?** Features su scale diverse (ore: 0-24, like: 0-4)
- **Effetto**: Ogni feature ha media=0, std=1
- **ML algorithms**: LogReg e SVM molto sensibili alle scale

```python
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y_cluster, test_size=0.2, random_state=42, stratify=y_cluster
    )
```

**ğŸ” Train/Test Split:**
- **80/20 split**: Standard per dataset di medie dimensioni
- **random_state=42**: ReproducibilitÃ  (sempre stesso split)
- **stratify=y_cluster**: Mantiene proporzioni cluster nel train/test
  - Train: ~307 cluster 0, 275 cluster 1  
  - Test: ~77 cluster 0, 68 cluster 1

```python
    models = {
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)
    }
```

**ğŸ” Scelta modelli:**

**Random Forest:**
```python
# Algoritmo: Bootstrap Aggregating (Bagging)
# 1. Crea 100 decision tree su campioni diversi
# 2. Ogni tree vota per una classe
# 3. Classe finale = voto maggioranza
```
- **Vantaggio**: Cattura interazioni non-lineari, robusto agli outlier
- **Svantaggio**: "Black box", puÃ² overfittare

**Logistic Regression:**
```python
# Formula: P(y=1) = 1 / (1 + e^(-(Î²â‚€ + Î²â‚xâ‚ + ... + Î²â‚™xâ‚™)))
```
- **Vantaggio**: Interpretabile, veloce, buona baseline
- **Svantaggio**: Assume relazioni lineari
- **max_iter=1000**: PiÃ¹ iterazioni per convergenza

```python
    for name, model in models.items():
        # Cross validation
        cv_scores = cross_val_score(model, X_train, y_train, cv=5)
        
        # Training
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
```

**ğŸ” Cross-Validation dettagliata:**
```python
# 5-Fold CV:
# Fold 1: Train[2,3,4,5] â†’ Test[1] â†’ Scoreâ‚
# Fold 2: Train[1,3,4,5] â†’ Test[2] â†’ Scoreâ‚‚
# Fold 3: Train[1,2,4,5] â†’ Test[3] â†’ Scoreâ‚ƒ
# Fold 4: Train[1,2,3,5] â†’ Test[4] â†’ Scoreâ‚„
# Fold 5: Train[1,2,3,4] â†’ Test[5] â†’ Scoreâ‚…
# Final Score = mean(Scoreâ‚...â‚…)
```

---

### **4. METRICHE CLASSIFICAZIONE**

```python
        accuracy = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred, average='weighted')
```

**ğŸ” Accuracy vs F1:**

**Accuracy:**
```python
# Formula: (TP + TN) / (TP + TN + FP + FN)
# Nostro risultato: 60.3%
```
- **Interpretazione**: 60.3% delle predizioni sono corrette
- **Problema**: PuÃ² essere misleading con classi sbilanciate

**F1-Score (weighted):**
```python
# Per ogni classe: F1áµ¢ = 2 Ã— (Precisionáµ¢ Ã— Recalláµ¢) / (Precisionáµ¢ + Recalláµ¢)
# Weighted F1 = Î£(F1áµ¢ Ã— náµ¢) / N
```
- **Vantaggio**: Bilancia precision e recall per ogni classe
- **Weighted**: DÃ  piÃ¹ peso alle classi numerose

---

### **5. REGRESSIONE**

```python
def regression_analysis(X, y_severity, feature_names):
    models = {
        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
        'Linear Regression': LinearRegression()
    }
```

**ğŸ” Differenze Classificazione â†’ Regressione:**

**Random Forest Regressor:**
```python
# Invece di voto maggioranza â†’ media delle predizioni
# Leaf value = media dei target nel leaf
```

**Linear Regression:**
```python
# Formula: y = Î²â‚€ + Î²â‚xâ‚ + Î²â‚‚xâ‚‚ + ... + Î²â‚™xâ‚™
# Trova Î² che minimizza: Î£(yáµ¢ - Å·áµ¢)Â²
```
- **Ordinary Least Squares (OLS)**: Soluzione analitica
- **Assunzioni**: LinearitÃ , omoscedasticitÃ , normalitÃ  residui

```python
        r2 = r2_score(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
```

**ğŸ” Metriche regressione:**

**RÂ² (Coefficient of Determination):**
```python
# Formula: RÂ² = 1 - (SS_res / SS_tot)
# SS_res = Î£(yáµ¢ - Å·áµ¢)Â²  (Sum of Squares Residual)
# SS_tot = Î£(yáµ¢ - È³)Â²   (Total Sum of Squares)
```
- **Interpretazione**: % varianza spiegata dal modello
- **Nostro 0.011**: Solo 1.1% della varianza in severity Ã¨ spiegata dalla musica
- **Range**: [0, 1] per modelli sensati, puÃ² essere negativo se pessimo

**RMSE (Root Mean Square Error):**
```python
# Formula: RMSE = âˆš(Î£(yáµ¢ - Å·áµ¢)Â² / n)
```
- **UnitÃ **: Stessa del target (severity score 0-3)
- **Nostro 1.875**: Errore medio di ~1.9 punti su scala 0-3
- **Interpretazione**: Modello sbaglia di circa 2 punti su 3

---

### **6. FEATURE IMPORTANCE**

```python
def feature_importance(class_results, reg_results, feature_names):
    rf_class = class_results['Random Forest']['model']
    
    class_importance = pd.DataFrame({
        'Feature': feature_names,
        'Importance': rf_class.feature_importances_
    }).sort_values('Importance', ascending=False)
```

**ğŸ” Come Random Forest calcola importance:**

```python
# Per ogni feature f e ogni tree t:
# 1. Calcola impurity decrease quando si split su f
# 2. Importance_f = Î£(weighted_impurity_decrease_f_t) / n_trees
# 3. Normalizza: Î£(all_importances) = 1
```

**Impurity measures:**
- **Classificazione**: Gini impurity = 1 - Î£páµ¢Â²
- **Regressione**: MSE = Î£(yáµ¢ - È³)Â²/n

**ğŸ¯ Nostri risultati:**
- **Hours per day: 63.8%** - Dominante!
- **Altri < 8%** ciascuno - Segnale debole

---

### **8. INTERPRETAZIONE RISULTATI**

```python
if class_results[class_best]['accuracy'] > 0.6:
    print("Le variabili musicali predicono discretamente i cluster")
else:
    print("Le variabili musicali predicono debolmente i cluster")
```

**ğŸ” Soglie interpretative:**

**Classificazione (Accuracy):**
- **> 90%**: Eccellente
- **80-90%**: Molto buono  
- **70-80%**: Buono
- **60-70%**: Discreto â† Noi siamo qui (60.3%)
- **50-60%**: Debole
- **< 50%**: Inutile

**Regressione (RÂ²):**
- **> 0.5**: Eccellente per scienze sociali
- **0.3-0.5**: Buono
- **0.1-0.3**: Moderato
- **0.02-0.1**: Piccolo ma significativo
- **< 0.02**: Trascurabile â† Noi siamo qui (0.011)

---



## ğŸ”¬ **VALIDITÃ€ SCIENTIFICA**

### **âœ… Punti di forza:**
1. **Sample size**: 727 soggetti (adeguato)
2. **Cross-validation**: Previene overfitting
3. **Multiple testing**: Testato piÃ¹ modelli
4. **Effect sizes**: Non solo p-values
5. **ReplicabilitÃ **: Codice e dati disponibili

### **âš ï¸ Limitazioni:**
1. **CausalitÃ **: Correlazione â‰  causazione
2. **Self-report**: Bias di desiderabilitÃ  sociale
3. **Cross-sectional**: Non longitudinale
4. **Cultural bias**: Campione principalmente occidentale

---

## ğŸ§  **TEORIA PSICOLOGICA SOTTOSTANTE**

### **Mood Regulation Theory:**
- Le persone usano la musica per regolare emozioni
- **Strategie**:
  - **Diversional**: Distrarsi (â‰ˆ ore di ascolto)
  - **Discharge**: Sfogare (â‰ˆ metal, rock)
  - **Strong experiences**: Intensificare emozioni

### **Uses and Gratifications Theory:**
- Le persone scelgono media per soddisfare bisogni specifici
- **Nostri risultati**: Chi ha problemi mentali usa piÃ¹ musica

---

## ğŸ¯ **CONCLUSIONI METODOLOGICHE**

1. **Pattern esistono** ma sono **deboli**
2. **Ore di ascolto** piÃ¹ predittive dei **generi**
3. **Clustering su salute mentale** funziona meglio che su musica
4. **ML conferma** i risultati statistici tradizionali
5. **Risultati robusti** attraverso multiple validazioni

**ğŸ“ Take-home message**: 
La musica E la salute mentale sono collegate, ma la relazione Ã¨ complessa e multifattoriale. I nostri metodi hanno catturato questo segnale debole ma significativo!

**ğŸ† Il successo Ã¨ aver trovato UN segnale in mezzo al rumore!**

